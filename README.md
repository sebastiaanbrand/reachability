# A decision diagram operation for reachability

## Files
* In `reach_algs/`, `bddmc.c` and `lddmc.c + ldd_custom.c` contain implementations of multiple reachability algorithms for BDDs and LDDs. The original implementations come from [here](https://github.com/trolando/sylvan/tree/master/examples), to which we have added the REACH algorithms presented in the paper. The BDD and LDD versions of REACH are internally called `go_rec` (line 847 in [bddmc.c](reach_algs/bddmc.c) and line 631 in [ldd_custom.c](reach_algs/ldd_custom.c)).
* `scripts/` contains a number of scripts for benchmarking and plotting.
* `sylvan/` contains the source of Sylvan. (For compatibility reasons we include a specific version of Sylvan rather than using an installed version.)

## Running the code

NOTE: steps 1 and 2 can be skipped when using the Docker image provided here: 

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7333633.svg)](https://doi.org/10.5281/zenodo.7333633)

### 1. Dependencies
For Ubuntu, the relevant dependencies can be installed with the following after running `sudo apt update`.

* C compilation tools (gcc, cmake): `sudo apt install cmake cmake-data build-essential`
* GMP: `sudo apt install libgmp-dev`
* Python3: `sudo apt install python3`
* Python packages:
    * pip: `sudo apt install python3-pip`
    * numpy: `sudo pip install numpy`
    * pandas: `sudo pip install pandas`
    * matplotlib: `sudo pip install matplotlib`
    * scipy: `sudo pip install scipy`

### 2. Benchmark data
The models used to benchmark can be downloaded from [here](https://surfdrive.surf.nl/files/index.php/s/W38OBT78zEZM9MN). The `models/` folder should be placed at the root of the repository folder.

**TODO**: cleanup models folder and upload updated version

* `models/` contains the models we used for benchmarking. Included are the original models, as well as `.bdd` and `.ldd` files generated by LTSmin. These `.bdd`/`.ldd` files contain decision diagrams for the transition relations and starting states and serve as the input for the reachability algorithms.

### 3. Compilation
Run `./compile_sources.sh` to (re)compile. This creates, in `reach_algs/build/`, two programs: `bddmc` and `lddmc`, which contain several reachability algorithms for BDDs and LDDs.

### 4. Running on individual models
From the root of the repository, the following runs REACH and saturation on the `adding.1.bdd` model with 1 worker/thread. Note that REACH requires `--merge-relations` to merge the partial relations.
```shell
$ ./reach_algs/build/bddmc models/beem/bdds/sloan/adding.1.bdd -s rec --merge-relations -w 1

$ ./reach_algs/build/bddmc models/beem/bdds/sloan/adding.1.bdd -s sat -w 1
```

And similarly for running REACH for the LDDs:
```shell
$ ./reach_algs/build/lddmc models/beem/ldds/sloan/adding.1.ldd -s rec --merge-relations -w 1

$ ./reach_algs/build/lddmc models/beem/ldds/sloan/adding.1.ldd -s sat -w 1
```

### 5. Reproducing experiments

The instructions in this README are set up to produce output data in the following directory structure.

```
bench_data/
├─ full/
|  ├─ parallel/                 # Fig. 5
|  ├─ reach-vs-its/             # Fig. 7
|  |  ├─ reach/
|  |  ├─ its/
|  ├─ reach-vs-saturation/      # Fig. 4, 6
├─ subset/
|  # same subfolders as full/
```


#### 5a. Reproducing experiments (subset)

* To generate a small subset of the data used for Figures 4 and 6 in the paper, run the command below. This runs (for each dataset; BEEM, Petri, Promela) a random selection of 10 small instances.
```shell
$ ./scripts/bench_subset.sh -n 10 -o subset/reach-vs-saturation small
``` 

* To reproduce the data in Figure 5 in the paper, a machine with (at least) 64 cores is required. Here we provide a command to run a small scale version of this (a subset of small instances and fewer (4) cores). Note that running for 1 core is required, since the plots show "1 core vs n cores".
```shell
$ ./scripts/bench_subset.sh -n 10 -w "1 4" -o subset/parallel test-par-only small
```

* To generate a small subset of the data used for Figure 7 in the paper, run:
```shell
TODO: make script to run subsets for Figure 7
```

The results of these benchmarks are written to `bench_data/subset/*/` as csv data. Running these commands multiple times appends the results of the new run to that of earlier runs.

#### 5b. Reproducing experiments (full)
From the root of the repository:

* To generate the data used for Figures 4 and 6 in the paper, run 
```shell
$ ./scripts/bench_all.sh -t 10m -o full/reach-vs-saturation bdd ldd beem-sloan petri-sloan promela-sloan
```


* To reproduce the data in Figure 5 in the paper, a machine with (at least) 64 cores is required. To generate the data, run
```shell
$ ./scripts/bench_all.sh -t 10m -w "1 16 64" -o full/parallel test-par-only bdd beem-sloan petri-sloan promela-sloan
```


* To reproduce the data in Figure 7 in the paper, run
```shell
$ ./scripts/bench_itstools.sh -o reach-vs-its/its_tools
$ ./scripts/bench_all.sh -t -o reach-vs-its/reach -t 10m ldd-static petri-sloan
```

The results of these benchmarks are written to `bench_data/full/*/` as csv data.


### 6. Generating plots
The following can be used to generate plots. Commands are given both for plotting full data and subset.

```bash
# Fig. 4: REACH vs saturation (full and subset)
$ python scripts/generate_plots.py saturation bench_data/full/reach-vs-saturation/
$ python scripts/generate_plots.py saturation bench_data/subset/reach-vs-saturation/

# Fig. 6: Effect of locality (full and subset)
$ python scripts/generate_plots.py locality bench_data/full/reach-vs-saturation/
$ python scripts/generate_plots.py locality bench_data/subset/reach-vs-saturation/

# Fig. 5: Parallel performance scatter plots (full and subset for 4 cores)
$ python scripts/generate_plots.py parallel-scatter bench_data/full/parallel/ 16 64
$ python scripts/generate_plots.py parallel-scatter bench_data/subset/parallel/ 4

# Fig. 7: comparison with ITS (full)
$ python scripts/aggregate_pnml-encode_time.py bench_data/full/reach-vs-its/reach/
$ python scripts/aggregate_its_data.py bench_data/full/reach-vs-its/
$ python scripts/generate_plots.py its bench_data/full/reach-vs-its/

# Fig. 7: comparison with ITS (subset)
$ python scripts/aggregate_pnml-encode_time.py bench_data/subset/reach-vs-its/reach/
$ python scripts/aggregate_its_data.py bench_data/subset/reach-vs-its/
$ python scripts/generate_plots.py its bench_data/subset/reach-vs-its/
```

**TODO**: entire pipeline for Fig. 7 needs to be double checked
**TODO**: probably also double check for other figures
